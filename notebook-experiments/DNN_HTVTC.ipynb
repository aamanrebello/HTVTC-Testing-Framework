{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0wEE8dzsg3R"
      },
      "source": [
        "#Dense Neural Network Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk3gJrpV0xzI"
      },
      "source": [
        "## 1. Initial Setup\n",
        "\n",
        "1.1. Begin by importing the necessary libraries. Seeds are set for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_DOsbftskh_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(1234)\n",
        "from keras.models import Sequential\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(123)\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wBTA12ts554"
      },
      "source": [
        "1.2. Load and preprocess the MNIST data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUUZo3vbs8jl"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "# Load and split data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "#Transform 3D X data into 2D \n",
        "X_train_flatten = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
        "X_test_flatten = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
        "\n",
        "#Normalise X data elements to all be in range [0,1]\n",
        "X_train_flatten = X_train_flatten.astype('float32')\n",
        "X_test_flatten = X_test_flatten.astype('float32')\n",
        "X_train_flatten /= 255\n",
        "X_test_flatten /= 255\n",
        "\n",
        "#Adjust y data so that numerical categorical labels become one-hot vectors of size 10\n",
        "Y_train_class = np_utils.to_categorical(y_train, 10)\n",
        "Y_test_class = np_utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yO_lETJuG84"
      },
      "source": [
        "1.3. Create a function to generate a 3-layer dense neural network, with parameterisable structure, to perform the prediction task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEdb6NSnMgNB"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = 784\n",
        "\n",
        "def create_network(L1_neurons, L2_neurons, **kwargs):\n",
        "  L1_activation = 'relu'\n",
        "  L2_activation = 'relu'\n",
        "  L3_activation = 'softmax'\n",
        "\n",
        "  L3_neurons = 10\n",
        "\n",
        "  if 'L1_activation' in kwargs.keys():\n",
        "    L1_activation = kwargs['L1_activation']\n",
        "  if 'L2_activation' in kwargs.keys():\n",
        "    L2_activation = kwargs['L2_activation']\n",
        "  if 'L3_activation' in kwargs.keys():\n",
        "    L3_activation = kwargs['L3_activation']\n",
        "  if 'L3_neurons' in kwargs.keys():\n",
        "    L3_neurons = kwargs['L3_neurons']\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Dense(L1_neurons, activation=L1_activation, input_shape=(INPUT_DIM,), name='L1'))\n",
        "  model.add(Dense(L2_neurons, activation=L2_activation, name='L2'))\n",
        "  model.add(Dense(L3_neurons, activation=L3_activation, name='L3'))\n",
        "\n",
        "  return model\n",
        "\n",
        "#Test the function\n",
        "test_model = create_network(64, 32, L3_neurons = 25)\n",
        "test_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6z_ol7IPeC-"
      },
      "source": [
        "1.4. Write a function which will accept the hyperparameters, generate the neural network and evaluate it against the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNS6chEaP40S"
      },
      "outputs": [],
      "source": [
        "def evaluate(L1_neurons, L2_neurons, **kwargs):\n",
        "  model = create_network(int(L1_neurons), int(L2_neurons), **kwargs)\n",
        "\n",
        "  loss_function = 'categorical_crossentropy'\n",
        "  optimizer = 'adam'\n",
        "  if 'loss_function' in kwargs.keys():\n",
        "    loss_function = kwargs['loss_function']\n",
        "  if 'optimizer' in kwargs.keys():\n",
        "    optimizer = kwargs['optimizer']\n",
        "\n",
        "  model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  batch_size = 32\n",
        "  if 'batch_size' in kwargs.keys():\n",
        "    batch_size = int(kwargs['batch_size'])\n",
        "\n",
        "  history = None\n",
        "  if 'epochs' in kwargs.keys():\n",
        "    epochs = int(kwargs['epochs'])\n",
        "    history = model.fit(X_train_flatten, Y_train_class, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "  else:\n",
        "    early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
        "    history = model.fit(X_train_flatten, Y_train_class, epochs=1000, batch_size=batch_size, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "  score = model.evaluate(X_test_flatten, Y_test_class, verbose=0)\n",
        "\n",
        "  return score[0]\n",
        "\n",
        "#Test the function\n",
        "evaluate(64, 32, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3xmXLMoyQJU"
      },
      "source": [
        "## 2. Hyperparameter Optimisation Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfc91rfsy53L"
      },
      "source": [
        "### 2.A. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O1JfeJAyh1s"
      },
      "source": [
        "#### 2.A.1. Import GitHub Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AC2qN25yo3Q"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/aamanrebello/HTVTC-Testing-Framework.git\n",
        "\n",
        "#Enable importing code from parent directory\n",
        "import os, sys\n",
        "final_HTVTC = os.path.abspath('./HTVTC-Testing-Framework/final-HTVTC')\n",
        "sys.path.insert(1, final_HTVTC)\n",
        "traditional_methods = os.path.abspath('./HTVTC-Testing-Framework/traditional-methods')\n",
        "sys.path.insert(1, traditional_methods)\n",
        "root = os.path.abspath('./HTVTC-Testing-Framework')\n",
        "sys.path.insert(1, root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_9QjArwyuX4"
      },
      "source": [
        "#### 2.A.2. Setup for HTVTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTsbH2yYyxde"
      },
      "outputs": [],
      "source": [
        "!pip install tensorly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ckUvVRCzFII"
      },
      "source": [
        "#### 2.A.3. Setup for Random Search, BO-TPE, CMA-ES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV6xlodGzVQg"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TlHU4omzbrq"
      },
      "source": [
        "#### 2.A.4. Setup for Hyperband"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1sZ1iWHziuI"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "def evaluate_with_budget(L1_neurons, L2_neurons, budget_fraction=1.0, **kwargs):\n",
        "  model = create_network(int(L1_neurons), int(L2_neurons), **kwargs)\n",
        "\n",
        "  loss_function = 'categorical_crossentropy'\n",
        "  optimizer = 'adam'\n",
        "  if 'loss_function' in kwargs.keys():\n",
        "    loss_function = kwargs['loss_function']\n",
        "  if 'optimizer' in kwargs.keys():\n",
        "    optimizer = kwargs['optimizer']\n",
        "\n",
        "  model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  batch_size = 32\n",
        "  if 'batch_size' in kwargs.keys():\n",
        "    batch_size = int(kwargs['batch_size'])\n",
        "\n",
        "  history = None\n",
        "  training_size = int(budget_fraction*len(X_train_flatten))\n",
        "  X_train_trunc = X_train_flatten[:training_size]\n",
        "  Y_train_trunc = Y_train_class[:training_size]\n",
        "\n",
        "  if 'epochs' in kwargs.keys():\n",
        "    epochs = int(kwargs['epochs'])\n",
        "    history = model.fit(X_train_trunc, Y_train_trunc, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "  else:\n",
        "    early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
        "    history = model.fit(X_train_trunc, Y_train_trunc, epochs=1000, batch_size=batch_size, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "  score = model.evaluate(X_test_flatten, Y_test_class, verbose=0)\n",
        "\n",
        "  return score[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvYA43RJzwJr"
      },
      "source": [
        "#### 2.A.5. Setup for BOHB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1Ss4uj1zzID"
      },
      "outputs": [],
      "source": [
        "!pip install hpbandster\n",
        "\n",
        "def evaluate_with_budget(L1_neurons, L2_neurons, budget_fraction=1.0, **kwargs):\n",
        "  model = create_network(int(L1_neurons), int(L2_neurons), **kwargs)\n",
        "\n",
        "  loss_function = 'categorical_crossentropy'\n",
        "  optimizer = 'adam'\n",
        "  if 'loss_function' in kwargs.keys():\n",
        "    loss_function = kwargs['loss_function']\n",
        "  if 'optimizer' in kwargs.keys():\n",
        "    optimizer = kwargs['optimizer']\n",
        "\n",
        "  model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  batch_size = 32\n",
        "  if 'batch_size' in kwargs.keys():\n",
        "    batch_size = int(kwargs['batch_size'])\n",
        "\n",
        "  history = None\n",
        "  training_size = int(budget_fraction*len(X_train_flatten))\n",
        "  X_train_trunc = X_train_flatten[:training_size]\n",
        "  Y_train_trunc = Y_train_class[:training_size]\n",
        "\n",
        "  if 'epochs' in kwargs.keys():\n",
        "    epochs = int(kwargs['epochs'])\n",
        "    history = model.fit(X_train_trunc, Y_train_trunc, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "  else:\n",
        "    early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
        "    history = model.fit(X_train_trunc, Y_train_trunc, epochs=1000, batch_size=batch_size, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "  score = model.evaluate(X_test_flatten, Y_test_class, verbose=0)\n",
        "\n",
        "  return score[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdjHF-pr0Z67"
      },
      "source": [
        "#### 2.A.6. Setup for BO-GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8L5Ymag0ckF"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/fmfn/BayesianOptimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cKTyRqG1bsd"
      },
      "source": [
        "### 2.B. Hyperparameter Optimisation Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTgKhi0vEXVA"
      },
      "source": [
        "#### 2.B.1. HTVTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlGAefhGZwr3"
      },
      "outputs": [],
      "source": [
        "from finalAlgoImplementation import final_HTVTC\n",
        "import regressionmetrics\n",
        "import classificationmetrics\n",
        "\n",
        "metric = classificationmetrics.indicatorFunction\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "\n",
        "func = evaluate\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "a = None\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "ranges_dict = {\n",
        "    'L1_neurons': {\n",
        "        'type': 'INTEGER',\n",
        "        'start': 20.0,\n",
        "        'end': 101.0,\n",
        "        'interval': 20.0\n",
        "        },\n",
        "    'L2_neurons': {\n",
        "        'type': 'INTEGER',\n",
        "        'start': 10.0,\n",
        "        'end': 51.00,\n",
        "        'interval': 20.0\n",
        "        },\n",
        "    'L1_activation': {\n",
        "        'type': 'CATEGORICAL',\n",
        "        'values': ['relu', 'tanh', 'sigmoid']\n",
        "        },\n",
        "    'L2_activation': {\n",
        "        'type': 'CATEGORICAL',\n",
        "        'values': ['relu', 'tanh', 'sigmoid']\n",
        "        },\n",
        "    'epochs': {\n",
        "        'type': 'CATEGORICAL',\n",
        "        'values': [1]\n",
        "    }\n",
        "  }\n",
        "\n",
        "recommended_combination, history = final_HTVTC(eval_func=func, ranges_dict=ranges_dict, metric=metric, max_completion_cycles=6, max_size_gridsearch=50)\n",
        "\n",
        "#End timer/memory profiler/CPU timer\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "\n",
        "#Find the true loss for the selcted combination\n",
        "true_value = func(metric=metric, **recommended_combination)\n",
        "\n",
        "print(f'hyperparameters: {recommended_combination}')\n",
        "print(f'history: {history}')\n",
        "print(f'True value: {true_value}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9Vc7oQzK6lk"
      },
      "source": [
        "#### 2.B.2. Random Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lAPaSx6LAaC"
      },
      "outputs": [],
      "source": [
        "from optuna.samplers import RandomSampler\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "func = evaluate\n",
        "\n",
        "def objective(trial):\n",
        "    L1_neurons = trial.suggest_int(\"L1_neurons\", 20, 101, step=1)\n",
        "    L2_neurons = trial.suggest_int(\"L2_neurons\", 10, 51, step=1)\n",
        "    L1_activation = trial.suggest_categorical(\"L1_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L2_activation = trial.suggest_categorical(\"L2_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    \n",
        "    return func(L1_neurons=L1_neurons, L2_neurons=L2_neurons, L1_activation=L1_activation, L2_activation=L2_activation, epochs=1)\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
        "study = optuna.create_study(sampler=RandomSampler())\n",
        "study.optimize(objective, n_trials=115)\n",
        "\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "print('\\n\\n\\n')\n",
        "print(f'Number of trials: {len(study.trials)}')\n",
        "print(f'Best trial: {study.best_trial}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO3y1gipNAIB"
      },
      "source": [
        "#### 2.B.3. BO-TPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iraMwuDoNFXx"
      },
      "outputs": [],
      "source": [
        "from optuna.samplers import TPESampler\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "func = evaluate\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    L1_neurons = trial.suggest_int(\"L1_neurons\", 20, 101, step=1)\n",
        "    L2_neurons = trial.suggest_int(\"L2_neurons\", 10, 51, step=1)\n",
        "    L1_activation = trial.suggest_categorical(\"L1_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L2_activation = trial.suggest_categorical(\"L2_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    \n",
        "    return func(L1_neurons=L1_neurons, L2_neurons=L2_neurons, L1_activation=L1_activation, L2_activation=L2_activation, epochs=1)\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
        "study = optuna.create_study(sampler=TPESampler())\n",
        "study.optimize(objective, n_trials=115)\n",
        "\n",
        "#End timer/memory profiler/CPU timer\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "print('\\n\\n\\n')\n",
        "print(f'Number of trials: {len(study.trials)}')\n",
        "print(f'Best trial: {study.best_trial}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pKiIMEL9CJp"
      },
      "source": [
        "#### 2.B.4. CMA-ES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3_JIhZa9GWE"
      },
      "outputs": [],
      "source": [
        "quantity = 'EXEC-TIME'\n",
        "func = evaluate\n",
        "\n",
        "def objective(trial):\n",
        "    L1_neurons = trial.suggest_int(\"L1_neurons\", 20, 101, step=1)\n",
        "    L2_neurons = trial.suggest_int(\"L2_neurons\", 10, 51, step=1)\n",
        "    L1_activation = trial.suggest_categorical(\"L1_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L2_activation = trial.suggest_categorical(\"L2_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    \n",
        "    return func(L1_neurons=L1_neurons, L2_neurons=L2_neurons, L1_activation=L1_activation, L2_activation=L2_activation, epochs=1)\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
        "sampler = optuna.samplers.CmaEsSampler()\n",
        "study = optuna.create_study(sampler=sampler)\n",
        "study.optimize(objective, n_trials=115)\n",
        "#resource_usage = getrusage(RUSAGE_SELF)\n",
        "\n",
        "#End timer/memory profiler/CPU timer\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "print('\\n\\n\\n')\n",
        "print(f'Number of trials: {len(study.trials)}')\n",
        "print(f'Best trial: {study.best_trial}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNvZjZtmK7hz"
      },
      "source": [
        "#### 2.B.5. Hyperband"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS5KWkUrK_AX"
      },
      "outputs": [],
      "source": [
        "from commonfunctions import generate_range\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "resolution = 0.2\n",
        "\n",
        "func = evaluate_with_budget\n",
        "\n",
        "def obtain_hyperparameters(trial):\n",
        "    L1_neurons = trial.suggest_int(\"L1_neurons\", 20, 101, step=1)\n",
        "    L2_neurons = trial.suggest_int(\"L2_neurons\", 10, 51, step=1)\n",
        "    L1_activation = trial.suggest_categorical(\"L1_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L2_activation = trial.suggest_categorical(\"L2_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "    return L1_neurons, L2_neurons, L1_activation, L2_activation\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    L1_neurons, L2_neurons, L1_activation, L2_activation = obtain_hyperparameters(trial)\n",
        "    metric_value = None\n",
        "\n",
        "    for fraction in generate_range(resolution,1,resolution):\n",
        "        metric_value = func(L1_neurons=L1_neurons, L2_neurons=L2_neurons, budget_fraction=fraction, L1_activation=L1_activation, L2_activation=L2_activation, epochs=1)\n",
        "        #Check for pruning\n",
        "        trial.report(metric_value, fraction)\n",
        "        if trial.should_prune():\n",
        "            print('=======================================================================================================')\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    #Would return the metric for fully trained model (on full dataset)\n",
        "    return metric_value\n",
        "    \n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=resolution, max_resource=1, reduction_factor=2\n",
        "    ),\n",
        ")\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "print('\\n\\n\\n')\n",
        "print(f'Number of trials: {len(study.trials)}')\n",
        "print(f'Best trial: {study.best_trial}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiWwQX-upQ74"
      },
      "source": [
        "#### 2.B.6. BOHB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx93SRMOp6_d"
      },
      "outputs": [],
      "source": [
        "import ConfigSpace as CS\n",
        "import ConfigSpace.hyperparameters as CSH\n",
        "import hpbandster.core.nameserver as hpns\n",
        "import hpbandster.core.result as hpres\n",
        "from hpbandster.core.worker import Worker\n",
        "from hpbandster.examples.commons import MyWorker\n",
        "from hpbandster.optimizers import BOHB as BOHB\n",
        "\n",
        "#To hide logs\n",
        "import logging\n",
        "logObj = logging.getLogger('noOutput')\n",
        "logObj.setLevel(100)\n",
        "\n",
        "#To hide warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "func = evaluate_with_budget\n",
        "\n",
        "#Define the worker\n",
        "class MyWorker(Worker):\n",
        "\n",
        "    def __init__(self, *args, sleep_interval=0, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "        self.sleep_interval = sleep_interval\n",
        "\n",
        "    def compute(self, config, budget, **kwargs):\n",
        "        res = func(**config, budget_fraction=budget, epochs=1)\n",
        "        \n",
        "        return({\n",
        "                    'loss': res,\n",
        "                    'info': res\n",
        "                })\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_configspace():\n",
        "        cs = CS.ConfigurationSpace()\n",
        "        L1_activation = CSH.CategoricalHyperparameter(\"L1_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "        L2_activation = CSH.CategoricalHyperparameter(\"L2_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "        cs.add_hyperparameters([L1_activation, L2_activation])\n",
        "\n",
        "        L1_neurons = CSH.UniformIntegerHyperparameter('L1_neurons', lower=20, upper=101)\n",
        "        L2_neurons = CSH.UniformIntegerHyperparameter('L2_neurons', lower=10, upper=51)\n",
        "        cs.add_hyperparameters([L1_neurons, L2_neurons])\n",
        "\n",
        "        return cs\n",
        "\n",
        "#Setup nameserver\n",
        "NS = hpns.NameServer(run_id='dnn', host='127.0.0.1', port=None)\n",
        "NS.start()\n",
        "\n",
        "#Start a worker\n",
        "w = MyWorker(sleep_interval = 0, nameserver='127.0.0.1',run_id='dnn', logger=logObj)\n",
        "w.run(background=True)\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "#Run the optimiser\n",
        "MAX_BUDGET = 1.0\n",
        "MIN_BUDGET = 0.2\n",
        "bohb = BOHB(  configspace = w.get_configspace(),\n",
        "              run_id = 'dnn', nameserver='127.0.0.1',\n",
        "              min_budget=MIN_BUDGET, max_budget=MAX_BUDGET,\n",
        "              logger=logObj\n",
        "           )\n",
        "res = bohb.run(n_iterations=50)\n",
        "\n",
        "#End timer/memory profiler/CPU timer\n",
        "quantity_result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    quantity_result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    quantity_result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, quantity_result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "\n",
        "#Shutdown\n",
        "bohb.shutdown(shutdown_workers=True)\n",
        "NS.shutdown()\n",
        "\n",
        "id2config = res.get_id2config_mapping()\n",
        "inc_id = res.get_incumbent_id()\n",
        "inc_runs = res.get_runs_by_id(inc_id)\n",
        "inc_run = inc_runs[-1]\n",
        "\n",
        "print('Best found configuration:', id2config[inc_id]['config'])\n",
        "print(f'Validation loss: {inc_run.loss}')\n",
        "print('A total of %i unique configurations were sampled.' % len(id2config.keys()))\n",
        "print('A total of %i runs were executed.' % len(res.get_all_runs()))\n",
        "print('Total budget corresponds to %.1f full function evaluations.'%(sum([r.budget for r in res.get_all_runs()])/MAX_BUDGET))\n",
        "print(f'{quantity}: {quantity_result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lY2BBEstdBD"
      },
      "source": [
        "#### 2.B.7. BO-GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg8uEoChtgrs"
      },
      "outputs": [],
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "trials = 95\n",
        "pval = 1\n",
        "\n",
        "func = evaluate\n",
        "\n",
        "def classify_activation(value):\n",
        "   if value < 5:\n",
        "      return 'relu'\n",
        "   elif value < 10:\n",
        "      return 'tanh'\n",
        "   else:\n",
        "      return 'sigmoid'\n",
        "\n",
        "def objective(L1_neurons, L2_neurons, L1_activation, L2_activation):\n",
        "    L1_neu_int = int(L1_neurons)\n",
        "    L2_neu_int = int(L2_neurons)\n",
        "\n",
        "    L1_act_str = classify_activation(L1_activation)\n",
        "    L2_act_str = classify_activation(L2_activation)\n",
        "\n",
        "    #subtract from 1 because the library only supports maximise\n",
        "    return pval - func(L1_neurons=L1_neu_int, L2_neurons=L2_neu_int, L1_activation=L1_act_str, L2_activation=L2_act_str, epochs=1)\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "#Begin optimisation\n",
        "pbounds = {'L1_neurons': (20, 101), 'L2_neurons': (10, 51), 'L1_activation': (0, 15), 'L2_activation': (0, 15)}\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=objective,\n",
        "    pbounds=pbounds,\n",
        "    random_state=1,\n",
        "    verbose = 0\n",
        ")\n",
        "\n",
        "optimizer.maximize(\n",
        "    init_points=10,\n",
        "    n_iter=trials,\n",
        ")\n",
        "\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "print('\\n\\n\\n')\n",
        "best = optimizer.max\n",
        "best_params = best['params']\n",
        "best_score = pval - best['target']\n",
        "print(f'Number of trials: {trials}')\n",
        "print(f'Best params: {best_params}')\n",
        "print(f'Best score: {best_score}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.C. Re-evaluate Specific Hyperparameter Combinations"
      ],
      "metadata": {
        "id": "6Kub1hT1uEIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialise the desired combination here\n",
        "combination_to_test = {}\n",
        "combination_to_test['epochs'] = 1\n",
        "\n",
        "#Evaluate 5 times\n",
        "true_value1 = evaluate(**combination_to_test)\n",
        "true_value2 = evaluate(**combination_to_test)\n",
        "true_value3 = evaluate(**combination_to_test)\n",
        "true_value4 = evaluate(**combination_to_test)\n",
        "true_value5 = evaluate(**combination_to_test)\n",
        "\n",
        "average = sum([true_value1, true_value2, true_value3, true_value4, true_value5])/5\n",
        "\n",
        "print(f'hyperparameters: {combination_to_test}')\n",
        "print(f'True values: {true_value1}, {true_value2}, {true_value3}, {true_value4}, {true_value5}')\n",
        "print(f'mean: {average}')"
      ],
      "metadata": {
        "id": "cdZ1b6fNuDjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzydARNZt7Tk"
      },
      "source": [
        "## 3. Display Backend Specifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSM52E5cw39i"
      },
      "outputs": [],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "id": "jflSFlvE-N05"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}