{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUwYLEYxJvM0"
      },
      "source": [
        "# CNN Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffS09wBdXskl"
      },
      "source": [
        "## 1. Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XElYvFcsYE00"
      },
      "source": [
        "1.1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flnfkQ1gJztJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lt1XKw6Yuso"
      },
      "source": [
        "1.2. Load and preprocess the MNIST data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jco2SP2QY0S3"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "shape = x_train.shape\n",
        "\n",
        "# Normalize and reshape the input images\n",
        "x_train = np.expand_dims(x_train.astype('float32'), -1)\n",
        "x_test = np.expand_dims(x_test.astype('float32'), -1)\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train_class = np_utils.to_categorical(y_train, 10)\n",
        "y_test_class = np_utils.to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA5ecWG3Z_oD"
      },
      "source": [
        "1.3. Create a function to generate a 3-layer CNN, with parameterisable structure, to perform the prediction task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qx7rtezmZ5U7"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = x_train.shape[1:]\n",
        "\n",
        "def create_network(L1_neurons, L2_neurons, **kwargs):\n",
        "  \n",
        "  L1_activation = 'relu'\n",
        "  L2_activation = 'relu'\n",
        "  L3_neurons = 10\n",
        "  L3_activation = 'softmax'\n",
        "\n",
        "  L1_stride = (3,3)\n",
        "  L2_stride = (3,3)\n",
        "\n",
        "  L1_pooling = (2,2)\n",
        "  L2_pooling = (2,2)\n",
        "\n",
        "  L1_padding = 'same'\n",
        "  L2_padding = 'same'\n",
        "\n",
        "  if 'L1_activation' in kwargs.keys():\n",
        "    L1_activation = kwargs['L1_activation']\n",
        "  if 'L2_activation' in kwargs.keys():\n",
        "    L2_activation = kwargs['L2_activation']\n",
        "  if 'L3_activation' in kwargs.keys():\n",
        "    L3_activation = kwargs['L3_activation']\n",
        "  if 'L3_neurons' in kwargs.keys():\n",
        "    L3_neurons = kwargs['L3_neurons']\n",
        "\n",
        "  if 'L1_stride' in kwargs.keys():\n",
        "    L1_stride = kwargs['L1_stride']\n",
        "  if 'L2_stride' in kwargs.keys():\n",
        "    L2_stride = kwargs['L2_stride']\n",
        "\n",
        "  if 'L1_pooling' in kwargs.keys():\n",
        "    L1_pooling = kwargs['L1_pooling']\n",
        "  if 'L2_pooling' in kwargs.keys():\n",
        "    L2_pooling = kwargs['L2_stride']\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(L1_neurons, L1_stride, padding=L1_padding, input_shape=INPUT_DIM))\n",
        "  model.add(Activation(L1_activation))\n",
        "  model.add(MaxPooling2D(pool_size=L1_pooling))\n",
        "  model.add(Conv2D(L2_neurons, L2_stride, padding=L2_padding))\n",
        "  model.add(Activation(L2_activation))\n",
        "  model.add(MaxPooling2D(pool_size=L2_pooling))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(L3_neurons))\n",
        "  model.add(Activation(L3_activation))\n",
        "\n",
        "  return model\n",
        "\n",
        "#Test the function\n",
        "test_model = create_network(64, 32, L3_neurons = 25)\n",
        "test_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvU5xtL_b9Ds"
      },
      "source": [
        "1.4. Write a function which will accept the hyperparameters, generate the neural network and evaluate it against the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTECTpnMb_S3"
      },
      "outputs": [],
      "source": [
        "def evaluate(L1_neurons, L2_neurons, **kwargs):\n",
        "  model = create_network(int(L1_neurons), int(L2_neurons), **kwargs)\n",
        "\n",
        "  loss_function = 'categorical_crossentropy'\n",
        "  optimizer = RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "  if 'loss_function' in kwargs.keys():\n",
        "    loss_function = kwargs['loss_function']\n",
        "  if 'optimizer' in kwargs.keys():\n",
        "    optimizer = kwargs['optimizer']\n",
        "\n",
        "  model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  batch_size = 32\n",
        "  if 'batch_size' in kwargs.keys():\n",
        "    batch_size = int(kwargs['batch_size'])\n",
        "\n",
        "  history = None\n",
        "  if 'epochs' in kwargs.keys():\n",
        "    epochs = int(kwargs['epochs'])\n",
        "    history = model.fit(x_train, y_train_class, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "  else:\n",
        "    early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
        "    history = model.fit(x_train, y_train_class, epochs=1000, batch_size=batch_size, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "  score = model.evaluate(x_test, y_test_class, verbose=0)\n",
        "\n",
        "  return score[0]\n",
        "\n",
        "#Test the function\n",
        "evaluate(10, 10, L1_pooling=(1,1), L2_pooling=(1,1), L1_stride=(1,1), L2_stride=(1,1), epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z8Lq3F_diYq"
      },
      "source": [
        "## 2. Hyperparameter Optimisation Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApZu88FKdvWC"
      },
      "source": [
        "### 2.A. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1rTVvSHd_x5"
      },
      "source": [
        "#### 2.A.1. Import GitHub Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoXG2kUUeHHO"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/aamanrebello/HTVTC-Testing-Framework.git\n",
        "\n",
        "#Enable importing code from parent directory\n",
        "import os, sys\n",
        "final_HTVTC = os.path.abspath('./HTVTC-Testing-Framework/final-HTVTC')\n",
        "sys.path.insert(1, final_HTVTC)\n",
        "traditional_methods = os.path.abspath('./HTVTC-Testing-Framework/traditional-methods')\n",
        "sys.path.insert(1, traditional_methods)\n",
        "root = os.path.abspath('./HTVTC-Testing-Framework')\n",
        "sys.path.insert(1, root)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IJT2juleKO7"
      },
      "source": [
        "#### 2.A.2. Setup for HTVTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwZku1TtePmH"
      },
      "outputs": [],
      "source": [
        "!pip install tensorly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZloqjVuZeVGH"
      },
      "source": [
        "#### 2.A.3. Setup for Random Search, BO-TPE, CMA-ES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjEDfm_Wehms"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TffMIIU_el-x"
      },
      "source": [
        "#### 2.A.4. Setup for Hyperband"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCH07NeQeqIP"
      },
      "outputs": [],
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "\n",
        "def evaluate_with_budget(L1_neurons, L2_neurons, budget_fraction=1.0, **kwargs):\n",
        "  model = create_network(int(L1_neurons), int(L2_neurons), **kwargs)\n",
        "\n",
        "  loss_function = 'categorical_crossentropy'\n",
        "  optimizer = RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "  if 'loss_function' in kwargs.keys():\n",
        "    loss_function = kwargs['loss_function']\n",
        "  if 'optimizer' in kwargs.keys():\n",
        "    optimizer = kwargs['optimizer']\n",
        "\n",
        "  model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  batch_size = 32\n",
        "  if 'batch_size' in kwargs.keys():\n",
        "    batch_size = int(kwargs['batch_size'])\n",
        "\n",
        "  history = None\n",
        "  training_size = int(budget_fraction*len(x_train))\n",
        "  x_train_trunc = x_train[:training_size]\n",
        "  y_train_trunc = y_train_class[:training_size]\n",
        "\n",
        "  if 'epochs' in kwargs.keys():\n",
        "    epochs = int(kwargs['epochs'])\n",
        "    history = model.fit(x_train_trunc, y_train_trunc, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "  else:\n",
        "    early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
        "    history = model.fit(x_train_trunc, y_train_trunc, epochs=1000, batch_size=batch_size, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "  score = model.evaluate(x_test, y_test_class, verbose=0)\n",
        "\n",
        "  return score[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQEDIZYVe2y1"
      },
      "source": [
        "#### 2.A.5. Setup for BOHB-HPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpcMstpve7qe"
      },
      "outputs": [],
      "source": [
        "!pip install bohb-hpo\n",
        "\n",
        "def evaluate_with_budget(L1_neurons, L2_neurons, budget_fraction=1.0, **kwargs):\n",
        "  model = create_network(int(L1_neurons), int(L2_neurons), **kwargs)\n",
        "\n",
        "  loss_function = 'categorical_crossentropy'\n",
        "  optimizer = RMSprop(learning_rate=0.0001, decay=1e-6)\n",
        "  if 'loss_function' in kwargs.keys():\n",
        "    loss_function = kwargs['loss_function']\n",
        "  if 'optimizer' in kwargs.keys():\n",
        "    optimizer = kwargs['optimizer']\n",
        "\n",
        "  model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  batch_size = 32\n",
        "  if 'batch_size' in kwargs.keys():\n",
        "    batch_size = int(kwargs['batch_size'])\n",
        "\n",
        "  history = None\n",
        "  training_size = int(budget_fraction*len(x_train))\n",
        "  x_train_trunc = x_train[:training_size]\n",
        "  y_train_trunc = y_train_class[:training_size]\n",
        "\n",
        "  if 'epochs' in kwargs.keys():\n",
        "    epochs = int(kwargs['epochs'])\n",
        "    history = model.fit(x_train_trunc, y_train_trunc, batch_size=batch_size, epochs=epochs, verbose=0)\n",
        "  else:\n",
        "    early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
        "    history = model.fit(x_train_trunc, y_train_trunc, epochs=1000, batch_size=batch_size, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "  score = model.evaluate(x_test, y_test_class, verbose=0)\n",
        "\n",
        "  return score[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA4C7_YBfBt7"
      },
      "source": [
        "#### 2.A.6. Setup for BO-GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luL3OVfEfH2U"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/fmfn/BayesianOptimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEWUcQEMfvyS"
      },
      "source": [
        "### 2.B. Hyperparameter Optimisation Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjx6N5-gf6yM"
      },
      "source": [
        "#### 2.B.1. HTVTC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "st5EOg9ff-dR"
      },
      "outputs": [],
      "source": [
        "from finalAlgoImplementation import final_HTVTC\n",
        "import regressionmetrics\n",
        "import classificationmetrics\n",
        "\n",
        "metric = classificationmetrics.indicatorFunction\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "\n",
        "func = evaluate\n",
        "\n",
        "def objective(L1_neurons, L2_neurons, L1_activation, L2_activation, L1_pooling_dim, L2_pooling_dim, L1_stride_dim, L2_stride_dim, **kwargs):\n",
        "  L1_pooling_dim_int = int(L1_pooling_dim)\n",
        "  L2_pooling_dim_int = int(L2_pooling_dim)\n",
        "  L1_stride_dim_int = int(L1_stride_dim)\n",
        "  L2_stride_dim_int = int(L2_stride_dim)\n",
        "  \n",
        "  L1_pooling = (L1_pooling_dim_int, L1_pooling_dim_int)\n",
        "  L2_pooling = (L2_pooling_dim_int, L2_pooling_dim_int)\n",
        "  L1_stride = (L1_stride_dim_int, L1_stride_dim_int)\n",
        "  L2_stride = (L2_stride_dim_int, L2_stride_dim_int)\n",
        "\n",
        "  return func(L1_neurons=L1_neurons, \n",
        "                L2_neurons=L2_neurons, \n",
        "                L1_activation=L1_activation, \n",
        "                L2_activation=L2_activation,\n",
        "                L1_pooling = L1_pooling,\n",
        "                L2_pooling = L2_pooling,\n",
        "                L1_stride = L1_stride,\n",
        "                L2_stride = L2_stride,\n",
        "                epochs = kwargs['epochs'])\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "a = None\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "ranges_dict = {\n",
        "    'L1_neurons': {\n",
        "        'type': 'INTEGER',\n",
        "        'start': 10.0,\n",
        "        'end': 40.0,\n",
        "        'interval': 10.0\n",
        "        },\n",
        "    'L2_neurons': {\n",
        "        'type': 'INTEGER',\n",
        "        'start': 10.0,\n",
        "        'end': 40.00,\n",
        "        'interval': 10.0\n",
        "        },\n",
        "    'L1_activation': {\n",
        "        'type': 'CATEGORICAL',\n",
        "        'values': ['relu', 'tanh', 'sigmoid']\n",
        "        },\n",
        "    'L2_activation': {\n",
        "        'type': 'CATEGORICAL',\n",
        "        'values': ['relu', 'tanh', 'sigmoid']\n",
        "        },\n",
        "    'L1_pooling_dim': {\n",
        "        'type': 'INTEGER',\n",
        "        'start': 1.0,\n",
        "        'end': 5.0,\n",
        "        'interval': 2.0\n",
        "        },\n",
        "    'L2_pooling_dim': {\n",
        "        'type': 'INTEGER',\n",
        "        'start': 1.0,\n",
        "        'end': 5.0,\n",
        "        'interval': 2.0\n",
        "        },\n",
        "    'L1_stride_dim': {\n",
        "        'type': 'INTEGER',\n",
        "        'start': 1.0,\n",
        "        'end': 5.0,\n",
        "        'interval': 2.0\n",
        "        },\n",
        "    'L2_stride_dim': {\n",
        "        'type': 'INTEGER',\n",
        "        'start': 1.0,\n",
        "        'end': 5.0,\n",
        "        'interval': 2.0\n",
        "        },\n",
        "    'epochs': {\n",
        "        'type': 'CATEGORICAL',\n",
        "        'values': [1]\n",
        "    }\n",
        "  }\n",
        "\n",
        "recommended_combination, history = final_HTVTC(eval_func=objective, ranges_dict=ranges_dict, metric=metric, max_completion_cycles=4)\n",
        "\n",
        "#End timer/memory profiler/CPU timer\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "\n",
        "print('OPT COMPLETED')\n",
        "#Find the true loss for the selcted combination\n",
        "true_value1 = func(metric=metric, **recommended_combination)\n",
        "true_value2 = func(metric=metric, **recommended_combination)\n",
        "true_value3 = func(metric=metric, **recommended_combination)\n",
        "true_value4 = func(metric=metric, **recommended_combination)\n",
        "true_value5 = func(metric=metric, **recommended_combination)\n",
        "\n",
        "print(f'hyperparameters: {recommended_combination}')\n",
        "print(f'history: {history}')\n",
        "print(f'True values: {true_value1}, {true_value2}, {true_value3}, {true_value4}, {true_value5}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWo89Dvgf_BA"
      },
      "source": [
        "#### 2.B.2. Random Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_5u1QN0igDaH"
      },
      "outputs": [],
      "source": [
        "from optuna.samplers import RandomSampler\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "func = evaluate\n",
        "\n",
        "def objective(trial):\n",
        "    L1_neurons = trial.suggest_int(\"L1_neurons\", 5, 40, step=1)\n",
        "    L2_neurons = trial.suggest_int(\"L2_neurons\", 5, 40, step=1)\n",
        "    L1_activation = trial.suggest_categorical(\"L1_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L2_activation = trial.suggest_categorical(\"L2_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L1_pooling_dim = trial.suggest_int(\"L1_pooling_dim\", 1, 5, step=1)\n",
        "    L2_pooling_dim = trial.suggest_int(\"L2_pooling_dim\", 1, 5, step=1)\n",
        "    L1_stride_dim = trial.suggest_int(\"L1_stride_dim\", 1, 5, step=1)\n",
        "    L2_stride_dim = trial.suggest_int(\"L2_stride_dim\", 1, 5, step=1)\n",
        "\n",
        "    L1_pooling = (L1_pooling_dim, L1_pooling_dim)\n",
        "    L2_pooling = (L2_pooling_dim, L2_pooling_dim)\n",
        "    L1_stride = (L1_stride_dim, L1_stride_dim)\n",
        "    L2_stride = (L2_stride_dim, L2_stride_dim)\n",
        "    \n",
        "    return func(L1_neurons=L1_neurons, \n",
        "                L2_neurons=L2_neurons, \n",
        "                L1_activation=L1_activation, \n",
        "                L2_activation=L2_activation,\n",
        "                L1_pooling = L1_pooling,\n",
        "                L2_pooling = L2_pooling,\n",
        "                L1_stride = L1_stride,\n",
        "                L2_stride = L2_stride,\n",
        "                epochs=1)\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
        "study = optuna.create_study(sampler=RandomSampler())\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "print('\\n\\n\\n')\n",
        "print(f'Number of trials: {len(study.trials)}')\n",
        "print(f'Best trial: {study.best_trial}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhfKw-__gIWl"
      },
      "source": [
        "#### 2.B.3. BO-TPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhRsJFOzgNEy"
      },
      "outputs": [],
      "source": [
        "from optuna.samplers import TPESampler\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "func = evaluate\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    L1_neurons = trial.suggest_int(\"L1_neurons\", 5, 40, step=1)\n",
        "    L2_neurons = trial.suggest_int(\"L2_neurons\", 5, 40, step=1)\n",
        "    L1_activation = trial.suggest_categorical(\"L1_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L2_activation = trial.suggest_categorical(\"L2_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L1_pooling_dim = trial.suggest_int(\"L1_pooling_dim\", 1, 5, step=1)\n",
        "    L2_pooling_dim = trial.suggest_int(\"L2_pooling_dim\", 1, 5, step=1)\n",
        "    L1_stride_dim = trial.suggest_int(\"L1_stride_dim\", 1, 5, step=1)\n",
        "    L2_stride_dim = trial.suggest_int(\"L2_stride_dim\", 1, 5, step=1)\n",
        "\n",
        "    L1_pooling = (L1_pooling_dim, L1_pooling_dim)\n",
        "    L2_pooling = (L2_pooling_dim, L2_pooling_dim)\n",
        "    L1_stride = (L1_stride_dim, L1_stride_dim)\n",
        "    L2_stride = (L2_stride_dim, L2_stride_dim)\n",
        "    \n",
        "    return func(L1_neurons=L1_neurons, \n",
        "                L2_neurons=L2_neurons, \n",
        "                L1_activation=L1_activation, \n",
        "                L2_activation=L2_activation,\n",
        "                L1_pooling = L1_pooling,\n",
        "                L2_pooling = L2_pooling,\n",
        "                L1_stride = L1_stride,\n",
        "                L2_stride = L2_stride,\n",
        "                epochs=1)\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
        "study = optuna.create_study(sampler=TPESampler())\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "#End timer/memory profiler/CPU timer\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "print('\\n\\n\\n')\n",
        "print(f'Number of trials: {len(study.trials)}')\n",
        "print(f'Best trial: {study.best_trial}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJEp1_GwgNi9"
      },
      "source": [
        "#### 2.B.4. CMA-ES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqtgsU1bgU-Y"
      },
      "outputs": [],
      "source": [
        "quantity = 'EXEC-TIME'\n",
        "func = evaluate\n",
        "\n",
        "def objective(trial):\n",
        "    L1_neurons = trial.suggest_int(\"L1_neurons\", 5, 40, step=1)\n",
        "    L2_neurons = trial.suggest_int(\"L2_neurons\", 5, 40, step=1)\n",
        "    L1_activation = trial.suggest_categorical(\"L1_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L2_activation = trial.suggest_categorical(\"L2_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L1_pooling_dim = trial.suggest_int(\"L1_pooling_dim\", 1, 5, step=1)\n",
        "    L2_pooling_dim = trial.suggest_int(\"L2_pooling_dim\", 1, 5, step=1)\n",
        "    L1_stride_dim = trial.suggest_int(\"L1_stride_dim\", 1, 5, step=1)\n",
        "    L2_stride_dim = trial.suggest_int(\"L2_stride_dim\", 1, 5, step=1)\n",
        "\n",
        "    L1_pooling = (L1_pooling_dim, L1_pooling_dim)\n",
        "    L2_pooling = (L2_pooling_dim, L2_pooling_dim)\n",
        "    L1_stride = (L1_stride_dim, L1_stride_dim)\n",
        "    L2_stride = (L2_stride_dim, L2_stride_dim)\n",
        "    \n",
        "    return func(L1_neurons=L1_neurons, \n",
        "                L2_neurons=L2_neurons, \n",
        "                L1_activation=L1_activation, \n",
        "                L2_activation=L2_activation,\n",
        "                L1_pooling = L1_pooling,\n",
        "                L2_pooling = L2_pooling,\n",
        "                L1_stride = L1_stride,\n",
        "                L2_stride = L2_stride,\n",
        "                epochs=1)\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
        "sampler = optuna.samplers.CmaEsSampler()\n",
        "study = optuna.create_study(sampler=sampler)\n",
        "study.optimize(objective, n_trials=20)\n",
        "#resource_usage = getrusage(RUSAGE_SELF)\n",
        "\n",
        "#End timer/memory profiler/CPU timer\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "print('\\n\\n\\n')\n",
        "print(f'Number of trials: {len(study.trials)}')\n",
        "print(f'Best trial: {study.best_trial}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDypoEMDgVej"
      },
      "source": [
        "#### 2.B.5. Hyperband"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOYndGgXga8f"
      },
      "outputs": [],
      "source": [
        "from commonfunctions import generate_range\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "resolution = 0.2\n",
        "\n",
        "func = evaluate_with_budget\n",
        "\n",
        "def objective(trial):\n",
        "    L1_neurons = trial.suggest_int(\"L1_neurons\", 5, 40, step=1)\n",
        "    L2_neurons = trial.suggest_int(\"L2_neurons\", 5, 40, step=1)\n",
        "    L1_activation = trial.suggest_categorical(\"L1_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L2_activation = trial.suggest_categorical(\"L2_activation\", ['relu', 'tanh', 'sigmoid'])\n",
        "    L1_pooling_dim = trial.suggest_int(\"L1_pooling_dim\", 1, 5, step=1)\n",
        "    L2_pooling_dim = trial.suggest_int(\"L2_pooling_dim\", 1, 5, step=1)\n",
        "    L1_stride_dim = trial.suggest_int(\"L1_stride_dim\", 1, 5, step=1)\n",
        "    L2_stride_dim = trial.suggest_int(\"L2_stride_dim\", 1, 5, step=1)\n",
        "\n",
        "    L1_pooling = (L1_pooling_dim, L1_pooling_dim)\n",
        "    L2_pooling = (L2_pooling_dim, L2_pooling_dim)\n",
        "    L1_stride = (L1_stride_dim, L1_stride_dim)\n",
        "    L2_stride = (L2_stride_dim, L2_stride_dim)\n",
        "    metric_value = None\n",
        "\n",
        "    for fraction in generate_range(resolution,1,resolution):\n",
        "        metric_value = func(L1_neurons=L1_neurons, \n",
        "                L2_neurons=L2_neurons,\n",
        "                budget_fraction=fraction, \n",
        "                L1_activation=L1_activation, \n",
        "                L2_activation=L2_activation,\n",
        "                L1_pooling = L1_pooling,\n",
        "                L2_pooling = L2_pooling,\n",
        "                L1_stride = L1_stride,\n",
        "                L2_stride = L2_stride,\n",
        "                epochs=1)\n",
        "        #Check for pruning\n",
        "        trial.report(metric_value, fraction)\n",
        "        if trial.should_prune():\n",
        "            print('=======================================================================================================')\n",
        "            raise optuna.TrialPruned()\n",
        "\n",
        "    #Would return the metric for fully trained model (on full dataset)\n",
        "    return metric_value\n",
        "    \n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "optuna.logging.set_verbosity(optuna.logging.FATAL)\n",
        "study = optuna.create_study(\n",
        "    direction=\"minimize\",\n",
        "    pruner=optuna.pruners.HyperbandPruner(\n",
        "        min_resource=resolution, max_resource=1, reduction_factor=2\n",
        "    ),\n",
        ")\n",
        "study.optimize(objective, n_trials=5)\n",
        "\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "print('\\n\\n\\n')\n",
        "print(f'Number of trials: {len(study.trials)}')\n",
        "print(f'Best trial: {study.best_trial}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb6XSI-MgjQs"
      },
      "source": [
        "#### 2.B.6. BOHB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-paV_6NngrXg"
      },
      "outputs": [],
      "source": [
        "from bohb import BOHB\n",
        "import bohb.configspace as cs\n",
        "\n",
        "func = evaluate_with_budget\n",
        "MAXVAL = 10\n",
        "\n",
        "def objective(fraction, L1_neurons, L2_neurons, L1_activation, L2_activation, L1_pooling_dim, L2_pooling_dim, L1_stride_dim, L2_stride_dim):\n",
        "    L1_pooling = (L1_pooling_dim, L1_pooling_dim)\n",
        "    L2_pooling = (L2_pooling_dim, L2_pooling_dim)\n",
        "    L1_stride = (L1_stride_dim, L1_stride_dim)\n",
        "    L2_stride = (L2_stride_dim, L2_stride_dim)\n",
        "    return func(L1_neurons=L1_neurons, \n",
        "                L2_neurons=L2_neurons,\n",
        "                budget_fraction=fraction, \n",
        "                L1_activation=L1_activation, \n",
        "                L2_activation=L2_activation,\n",
        "                L1_pooling = L1_pooling,\n",
        "                L2_pooling = L2_pooling,\n",
        "                L1_stride = L1_stride,\n",
        "                L2_stride = L2_stride,\n",
        "                epochs=1)\n",
        "    \n",
        "def evaluate(params, n_iterations):\n",
        "    fraction = n_iterations/MAXVAL\n",
        "    return objective(**params, fraction=fraction)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    L1_neurons = cs.IntegerUniformHyperparameter('L1_neurons', 5, 40)\n",
        "    L2_neurons = cs.IntegerUniformHyperparameter('L2_neurons', 5, 40)\n",
        "    L1_activation = cs.CategoricalHyperparameter('L1_activation', ['relu', 'tanh', 'sigmoid'])\n",
        "    L2_activation = cs.CategoricalHyperparameter('L2_activation', ['relu', 'tanh', 'sigmoid'])\n",
        "    L1_pooling_dim = cs.IntegerUniformHyperparameter('L1_pooling_dim', 1, 5)\n",
        "    L2_pooling_dim = cs.IntegerUniformHyperparameter('L2_pooling_dim', 1, 5)\n",
        "    L1_stride_dim = cs.IntegerUniformHyperparameter('L1_stride_dim', 1, 5)\n",
        "    L2_stride_dim = cs.IntegerUniformHyperparameter('L2_stride_dim', 1, 5)\n",
        "    configspace = cs.ConfigurationSpace([L1_neurons, L2_neurons, L1_activation, L2_activation, L1_pooling_dim, L2_pooling_dim, L1_stride_dim, L2_stride_dim])\n",
        "\n",
        "    opt = BOHB(configspace, evaluate, max_budget=MAXVAL, min_budget=1, eta=2)\n",
        "\n",
        "    quantity = 'EXEC-TIME'\n",
        "\n",
        "    #Start timer/memory profiler/CPU timer\n",
        "    start_time = None\n",
        "    if quantity == 'EXEC-TIME':\n",
        "        import time\n",
        "        start_time = time.perf_counter_ns()\n",
        "    elif quantity == 'CPU-TIME':\n",
        "        import time\n",
        "        start_time = time.process_time_ns()\n",
        "    elif quantity == 'MAX-MEMORY':\n",
        "        import tracemalloc\n",
        "        tracemalloc.start()\n",
        "\n",
        "    logs = opt.optimize()\n",
        "\n",
        "    #End timer/memory profiler/CPU timer\n",
        "    result = None\n",
        "    if quantity == 'EXEC-TIME':\n",
        "        end_time = time.perf_counter_ns()\n",
        "        result = end_time - start_time\n",
        "    elif quantity == 'CPU-TIME':\n",
        "        end_time = time.process_time_ns()\n",
        "        result = end_time - start_time\n",
        "    elif quantity == 'MAX-MEMORY':\n",
        "        _, result = tracemalloc.get_traced_memory()\n",
        "        tracemalloc.stop()\n",
        "    \n",
        "    print(logs)\n",
        "    print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7wseNO5gtQL"
      },
      "source": [
        "#### 2.B.7. BO-GP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unGwkdcpgvy_"
      },
      "outputs": [],
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "quantity = 'EXEC-TIME'\n",
        "trials = 15\n",
        "pval = 1\n",
        "\n",
        "func = evaluate\n",
        "\n",
        "def classify_activation(value):\n",
        "   if value < 5:\n",
        "      return 'relu'\n",
        "   elif value < 10:\n",
        "      return 'tanh'\n",
        "   else:\n",
        "      return 'sigmoid'\n",
        "\n",
        "def objective(L1_neurons, L2_neurons, L1_activation, L2_activation, L1_pooling_dim, L2_pooling_dim, L1_stride_dim, L2_stride_dim):\n",
        "    L1_neu_int = int(L1_neurons)\n",
        "    L2_neu_int = int(L2_neurons)\n",
        "\n",
        "    L1_act_str = classify_activation(L1_activation)\n",
        "    L2_act_str = classify_activation(L2_activation)\n",
        "\n",
        "    L1_pooling_dim_int = int(L1_pooling_dim)\n",
        "    L2_pooling_dim_int = int(L2_pooling_dim)\n",
        "    L1_stride_dim_int = int(L1_stride_dim)\n",
        "    L2_stride_dim_int = int(L2_stride_dim)\n",
        "\n",
        "    L1_pooling = (L1_pooling_dim_int, L1_pooling_dim_int)\n",
        "    L2_pooling = (L2_pooling_dim_int, L2_pooling_dim_int)\n",
        "    L1_stride = (L1_stride_dim_int, L1_stride_dim_int)\n",
        "    L2_stride = (L2_stride_dim_int, L2_stride_dim_int)\n",
        "\n",
        "    #subtract from 1 because the library only supports maximise\n",
        "    funcval = func(L1_neurons=L1_neurons, \n",
        "                L2_neurons=L2_neurons, \n",
        "                L1_activation=L1_act_str, \n",
        "                L2_activation=L2_act_str,\n",
        "                L1_pooling = L1_pooling,\n",
        "                L2_pooling = L2_pooling,\n",
        "                L1_stride = L1_stride,\n",
        "                L2_stride = L2_stride,\n",
        "                epochs=1)\n",
        "    return pval - funcval\n",
        "\n",
        "#Start timer/memory profiler/CPU timer\n",
        "start_time = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    import time\n",
        "    start_time = time.perf_counter_ns()\n",
        "elif quantity == 'CPU-TIME':\n",
        "    import time\n",
        "    start_time = time.process_time_ns()\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    import tracemalloc\n",
        "    tracemalloc.start()\n",
        "\n",
        "#Begin optimisation\n",
        "pbounds = {\n",
        "    'L1_neurons': (5, 40), \n",
        "    'L2_neurons': (5, 40), \n",
        "    'L1_activation': (0, 15), \n",
        "    'L2_activation': (0, 15),\n",
        "    'L1_pooling_dim': (1,5),\n",
        "    'L2_pooling_dim': (1,5),\n",
        "    'L1_stride_dim': (1,5),\n",
        "    'L2_stride_dim': (1,5),\n",
        "    }\n",
        "\n",
        "optimizer = BayesianOptimization(\n",
        "    f=objective,\n",
        "    pbounds=pbounds,\n",
        "    random_state=1,\n",
        "    verbose = 0\n",
        ")\n",
        "\n",
        "optimizer.maximize(\n",
        "    init_points=10,\n",
        "    n_iter=trials,\n",
        ")\n",
        "\n",
        "result = None\n",
        "if quantity == 'EXEC-TIME':\n",
        "    end_time = time.perf_counter_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'CPU-TIME':\n",
        "    end_time = time.process_time_ns()\n",
        "    result = end_time - start_time\n",
        "elif quantity == 'MAX-MEMORY':\n",
        "    _, result = tracemalloc.get_traced_memory()\n",
        "    tracemalloc.stop()\n",
        "    \n",
        "best = optimizer.max\n",
        "best_params = best['params']\n",
        "best_score = pval - best['target']\n",
        "print(f'Number of trials: {trials}')\n",
        "print(f'Best params: {best_params}')\n",
        "print(f'Best score: {best_score}')\n",
        "print(f'{quantity}: {result}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8mw0CYtbPV8"
      },
      "source": [
        "### 2.C. Display Background Specifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0z_8Oy4a5Vz"
      },
      "outputs": [],
      "source": [
        "!lscpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CFWrK10bN9z"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}